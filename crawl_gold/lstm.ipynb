#!/usr/bin/env python
# coding: utf-8

# In[4]:


import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.model_selection import train_test_split


# In[6]:


file_path = "D:/crawdata/crawl_gold/gold.csv"

df = pd.read_csv(file_path)
df.head(20)


# In[7]:


df.info()


# In[9]:


df.describe()


# In[10]:


features = ['Open', 'High', 'Low', 'Close', 'Adj close']
df_features = df[features]
print(df_features)


# In[11]:


scalers = {}
for feature in features:
    scalers[feature] = MinMaxScaler(feature_range=(0, 1))
    df_features[feature] = scalers[feature].fit_transform(df_features[feature].values.reshape(-1,1))


# In[13]:


look_back = 7


# In[14]:


def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), :]
        X.append(a)
        Y.append(dataset[i + look_back, :])
    return np.array(X), np.array(Y)

data_scaled = df_features.values
X, Y = create_dataset(data_scaled, look_back)


# In[15]:


X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))


# In[16]:


train_size = int(len(X) * 0.7)
test_size = len(X) - train_size

X_train, X_test = X[:train_size], X[train_size:]
Y_train, Y_test = Y[:train_size], Y[train_size:]

print(f'Total samples: {len(X)}')
print(f'Training samples: {train_size}')
print(f'Testing samples: {test_size}')


# In[19]:


model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(look_back, X.shape[2])))
model.add(LSTM(50))
model.add(Dense(X.shape[2]))

model.compile(loss='mean_squared_error', optimizer='adam')


# In[20]:


model.fit(X_train, Y_train, epochs=100, batch_size=1, verbose=2)


# In[21]:


train_predict = model.predict(X_train)
test_predict = model.predict(X_test)


# In[22]:


for i, feature in enumerate(features):
    train_predict[:, i] = scalers[feature].inverse_transform(train_predict[:, i].reshape(-1, 1)).reshape(-1)
    test_predict[:, i] = scalers[feature].inverse_transform(test_predict[:, i].reshape(-1, 1)).reshape(-1)
    Y_train[:, i] = scalers[feature].inverse_transform(Y_train[:, i].reshape(-1, 1)).reshape(-1)
    Y_test[:, i] = scalers[feature].inverse_transform(Y_test[:, i].reshape(-1, 1)).reshape(-1)


# In[23]:


train_score = np.sqrt(np.mean((train_predict - Y_train)**2, axis=0))
test_score = np.sqrt(np.mean((test_predict - Y_test)**2, axis=0))


# In[25]:


for i, feature in enumerate(features):
    print(f'{feature} Train Score: {train_score[i]:.2f} RMSE')
    print(f'{feature} Test Score: {test_score[i]:.2f} RMSE')


# In[26]:


def mean_absolute_percentage_error(y_true, y_pred):
    """
    Tính Mean Absolute Percentage Error (MAPE)
    
    Tham số:
    y_true : array-like of shape (n_samples,)
        Giá trị thực tế.
    y_pred : array-like of shape (n_samples,)
        Giá trị dự đoán.
        
    Trả về:
    float
        Giá trị của MAPE.
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# Bộ dữ liệu
y_true = [2326.4, 2347.5, 2322.6, 2344.1, 2336.9]
y_pred = [2354.1, 2325.5, 2346.6, 2322.9, 2342.9]

# Tính toán MAPE
mape = mean_absolute_percentage_error(y_true, y_pred)

# In ra kết quả
print("Mean Absolute Percentage Error (MAPE):", mape)


# In[ ]:




